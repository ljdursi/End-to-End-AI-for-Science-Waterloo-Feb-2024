{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Spring Mass Problem using PINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have familiarized ourselves with the Modulus APIs and solved the Projectile motion, 1-Dimensional diffusion equation in a single simulation and parameterized setting and Weather Forecasting using Navier-Stokes PDE, we move to the next application of PINNs. In this notebook, we will solve the system of differential equations that define a coupled spring mass problem. In this tutorial, we will see how to solve transient problems over small time intervals easily by treating time as a continuous variable. We will also use PINNs to solve the problem in an inverse setting where we have the solution data, and we use PINN to find the coefficient of the ODE.\n",
    "\n",
    "You can refer to the [Modulus User Documentation](https://docs.nvidia.com/deeplearning/modulus/index.html#) for more examples of solving different types of time domain problems and inverse problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents of the Notebook\n",
    "- [Solving the Spring Mass Problem using PINNs](#Solving-the-Spring-Mass-Problem-using-PINNs)\n",
    "    - [Problem Description](#Problem-Description)\n",
    "    - [Case Setup and defining the ODE](#Case-Setup-and-defining-the-ODE)\n",
    "    - [Step 1,2 & 3: Defining the Neural Network nodes, Creating Geometry and defining constraints (ICs, BCs, PDEs)](#Step-1,2-&-3:-Defining-the-Neural-Network-nodes,-Creating-Geometry-and-defining-constraints-(ICs,-BCs,-PDEs))\n",
    "    - [Step 4: Adding Validation data](#Step-4:-Adding-Validation-data)\n",
    "    - [Step 5: Hydra configuration](#Step-5:-Hydra-configuration)\n",
    "    - [Step 6: Solver and training](#Step-6:-Solver-and-training)\n",
    "    - [Visualizing the solution](#Visualizing-the-solution)\n",
    "- [Solving the Inverse Problem](#Solving-the-Inverse-Problem)\n",
    "    - [Case Setup](#Case-Setup)\n",
    "    - [Step 1,2 & 3:  Defining the equations, Networks and Nodes for an Inverse problem](#Step-1,2-&-3:--Defining-the-equations,-Networks-and-Nodes-for-an-Inverse-problem)\n",
    "    - [Step 4: Adding Monitors](#Step-4:-Adding-Monitors)\n",
    "    - [Step 5: Hydra configuration](#Step-5:-Hydra-configuration)\n",
    "    - [Step 6: Solver and Training](#Step-6:-Solver-and-Training)\n",
    "    - [Visualizing the solution - Inverse spring problem](#Visualizing-the-solution---Inverse-spring-problem)\n",
    "\n",
    "#### Learning Outcomes\n",
    "- How to use Modulus to simulate transient problems using PINNs by treating time as a continuous variable\n",
    "- How to use Modulus to solve a inverse problem\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the Spring Mass Problem using PINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description\n",
    "\n",
    "In this tutorial, we will solve a simple spring mass system as shown in the figure below. The system shows three masses attached to each other by four springs. The springs slide along a frictionless horizontal surface. The masses are assumed to be point masses, and the springs are mass-less.\n",
    "<center><img src=\"images/spring_mass_drawing.png\" alt=\"Drawing\" style=\"width:500px\" /></center>\n",
    "\n",
    "\n",
    "The model's equations are given as below:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "m_1 x_1''(t) &= -k_1 x_1(t) + k_2(x_2(t) - x_1(t)),\\\\\n",
    "m_2 x_2''(t) &= -k_2 (x_2(t) - x_1(t))+ k_3(x_3(t) - x_2(t)),\\\\\n",
    "m_3 x_3''(t) &= -k_3 (x_3(t) - x_2(t)) - k_4 x_3(t). \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "Where, $x_1(t), x_2(t), \\text{and } x_3(t)$ denote the mass positions along the horizontal surface measured from their equilibrium position, positive right and negative left. As shown in the figure, the first and the last spring are fixed to the walls. \n",
    "For the first part of the tutorial, we will assume the following conditions:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "[m_1, m_2, m_3] &= [1, 1, 1],\\\\\n",
    "[k_1, k_2, k_3, k_4] &= [2, 1, 1, 2],\\\\\n",
    "[x_1(0), x_2(0), x_3(0)] &= [1, 0, 0],\\\\\n",
    "[x_1'(0), x_2'(0), x_3'(0)] &= [0, 0, 0].\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Setup and defining the ODE\n",
    "\n",
    "Now that we have our problem defined, let's look at the code required to solve it using Modulus. \n",
    "\n",
    "#### Note : Now we will describe the contents of the [`spring_mass_solver.py`](../../source_code/spring_mass/spring_mass_solver.py) script "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the differential equations for the problem\n",
    "\n",
    "This process is similar to the previous tutorial. We will write each parameter ($k's \\text{ and } m's$) as a function and substitute it as a number if it is a constant. This will allow us to parameterize these constants by passing them as a string. This will also allow us to solve the inverse problem where either of these quantities is unknown and can be predicted by the neural network. The PDE is defined in <a href=\"../../source_code/spring_mass/spring_mass_ode.py\" rel=\"nofollow\"><code>spring_mass_ode.py</code></a> script \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sympy import Symbol, Function, Number\n",
    "from modulus.sym.eq.pde import PDE\n",
    "\n",
    "\n",
    "class SpringMass(PDES):\n",
    "    name = \"SpringMass\"\n",
    "\n",
    "    def __init__(self, k=(2, 1, 1, 2), m=(1, 1, 1)):\n",
    "\n",
    "        self.k = k\n",
    "        self.m = m\n",
    "\n",
    "        k1 = k[0]\n",
    "        k2 = k[1]\n",
    "        k3 = k[2]\n",
    "        k4 = k[3]\n",
    "        m1 = m[0]\n",
    "        m2 = m[1]\n",
    "        m3 = m[2]\n",
    "\n",
    "        t = Symbol(\"t\")\n",
    "        input_variables = {\"t\": t}\n",
    "\n",
    "        x1 = Function(\"x1\")(*input_variables)\n",
    "        x2 = Function(\"x2\")(*input_variables)\n",
    "        x3 = Function(\"x3\")(*input_variables)\n",
    "\n",
    "        if type(k1) is str:\n",
    "            k1 = Function(k1)(*input_variables)\n",
    "        elif type(k1) in [float, int]:\n",
    "            k1 = Number(k1)\n",
    "        if type(k2) is str:\n",
    "            k2 = Function(k2)(*input_variables)\n",
    "        elif type(k2) in [float, int]:\n",
    "            k2 = Number(k2)\n",
    "        if type(k3) is str:\n",
    "            k3 = Function(k3)(*input_variables)\n",
    "        elif type(k3) in [float, int]:\n",
    "            k3 = Number(k3)\n",
    "        if type(k4) is str:\n",
    "            k4 = Function(k4)(*input_variables)\n",
    "        elif type(k4) in [float, int]:\n",
    "            k4 = Number(k4)\n",
    "\n",
    "        if type(m1) is str:\n",
    "            m1 = Function(m1)(*input_variables)\n",
    "        elif type(m1) in [float, int]:\n",
    "            m1 = Number(m1)\n",
    "        if type(m2) is str:\n",
    "            m2 = Function(m2)(*input_variables)\n",
    "        elif type(m2) in [float, int]:\n",
    "            m2 = Number(m2)\n",
    "        if type(m3) is str:\n",
    "            m3 = Function(m3)(*input_variables)\n",
    "        elif type(m3) in [float, int]:\n",
    "            m3 = Number(m3)\n",
    "\n",
    "        self.equations = {}\n",
    "        self.equations[\"ode_x1\"] = m1 * (x1.diff(t)).diff(t) + k1 * x1 - k2 * (x2 - x1)\n",
    "        self.equations[\"ode_x2\"] = (\n",
    "            m2 * (x2.diff(t)).diff(t) + k2 * (x2 - x1) - k3 * (x3 - x2)\n",
    "        )\n",
    "        self.equations[\"ode_x3\"] = m3 * (x3.diff(t)).diff(t) + k3 * (x3 - x2) + k4 * x3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1,2 & 3: Defining the Neural Network nodes, Creating Geometry and defining constraints (ICs, BCs, PDEs)\n",
    "\n",
    "Once we have the ODEs defined, we can easily form the constraints needed for optimization as seen in earlier tutorials. This example uses <code>Point1D</code> geometry to create the point mass. We will also have to define the time range of the solution and create a symbol for time ($t$) to define the initial condition, etc. in the domain. The below code shows the geometry definition for this problem. Note that this tutorial does not use the x-coordinate ($x$) information of the point, it is only used to sample a point in space. The point is assigned different values for variable $t$ only (initial conditions and ODEs over the time-range). The code to generate the nodes and relevant constraints is shown below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sympy import Symbol, Eq\n",
    "\n",
    "import modulus\n",
    "from modulus.sym.hydra import ModulusConfig, instantiate_arch\n",
    "from modulus.sym.solver import Solver\n",
    "from modulus.sym.domain import Domain\n",
    "from modulus.sym.geometry.primitives_1d import Point1D\n",
    "from modulus.sym.geometry import Parameterization\n",
    "from modulus.sym.domain.constraint import (\n",
    "    PointwiseBoundaryConstraint,\n",
    "    PointwiseBoundaryConstraint,\n",
    ")\n",
    "\n",
    "from spring_mass_ode import SpringMass\n",
    "\n",
    "\n",
    "@modulus.sym.main(config_path=\"conf\", config_name=\"config\")\n",
    "def run(cfg: ModulusConfig) -> None:\n",
    "    # make list of nodes to unroll graph on\n",
    "    sm = SpringMass(k=(2, 1, 1, 2), m=(1, 1, 1))\n",
    "    sm_net = instantiate_arch(\n",
    "        input_keys=[Key(\"t\")],\n",
    "        output_keys=[Key(\"x1\"), Key(\"x2\"), Key(\"x3\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "    nodes = sm.make_nodes() + [\n",
    "        sm_net.make_node(name=\"spring_mass_network\", jit=cfg.jit)\n",
    "    ]\n",
    "\n",
    "    # add constraints to solver\n",
    "    # make geometry\n",
    "    geo = Point1D(0)\n",
    "    t_max = 10.0\n",
    "    t_symbol = Symbol(\"t\")\n",
    "    x = Symbol(\"x\")\n",
    "    time_range = {t_symbol: (0, t_max)}\n",
    "\n",
    "    # make domain\n",
    "    domain = Domain()\n",
    "\n",
    "    # initial conditions\n",
    "    IC = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"x1\": 1.0, \"x2\": 0, \"x3\": 0, \"x1__t\": 0, \"x2__t\": 0, \"x3__t\": 0},\n",
    "        batch_size=cfg.batch_size.IC,\n",
    "        lambda_weighting={\n",
    "            \"x1\": 1.0,\n",
    "            \"x2\": 1.0,\n",
    "            \"x3\": 1.0,\n",
    "            \"x1__t\": 1.0,\n",
    "            \"x2__t\": 1.0,\n",
    "            \"x3__t\": 1.0,\n",
    "        },\n",
    "        parameterization=Parameterization({t_symbol: 0}),\n",
    "    )\n",
    "    domain.add_constraint(IC, name=\"IC\")\n",
    "\n",
    "    # solve over given time period\n",
    "    interior = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"ode_x1\": 0.0, \"ode_x2\": 0.0, \"ode_x3\": 0.0},\n",
    "        batch_size=cfg.batch_size.interior,\n",
    "        parameterization=Parameterization(time_range),\n",
    "    )\n",
    "    domain.add_constraint(interior, \"interior\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Adding Validation data\n",
    "\n",
    "Next, we will define the validation data for this problem. The solution to this problem can be obtained analytically, and the expression can be coded into dictionaries of numpy arrays for `x1`, `x2`, and `x3`. This part of the code is similar to the previous diffusion example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # add validation data\n",
    "    deltaT = 0.001\n",
    "    t = np.arange(0, t_max, deltaT)\n",
    "    t = np.expand_dims(t, axis=-1)\n",
    "    invar_numpy = {\"t\": t}\n",
    "    outvar_numpy = {\n",
    "        \"x1\": (1 / 6) * np.cos(t)\n",
    "        + (1 / 2) * np.cos(np.sqrt(3) * t)\n",
    "        + (1 / 3) * np.cos(2 * t),\n",
    "        \"x2\": (2 / 6) * np.cos(t)\n",
    "        + (0 / 2) * np.cos(np.sqrt(3) * t)\n",
    "        - (1 / 3) * np.cos(2 * t),\n",
    "        \"x3\": (1 / 6) * np.cos(t)\n",
    "        - (1 / 2) * np.cos(np.sqrt(3) * t)\n",
    "        + (1 / 3) * np.cos(2 * t),\n",
    "    }\n",
    "    validator = PointwiseValidator(\n",
    "        nodes=nodes, invar=invar_numpy, true_outvar=outvar_numpy, batch_size=1024\n",
    "    )\n",
    "    domain.add_validator(validator)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Hydra configuration\n",
    "\n",
    "More information on the available configurations can be found in [Modulus Configuration](https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/features/configuration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "defaults :\n",
    "  - modulus_default\n",
    "  - arch:\n",
    "      - fully_connected\n",
    "  - scheduler: tf_exponential_lr\n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "save_filetypes : \"vtk,npz\"\n",
    "\n",
    "scheduler:\n",
    "  decay_rate: 0.95\n",
    "  decay_steps: 100\n",
    "\n",
    "training:\n",
    "  rec_results_freq: 1000\n",
    "  max_steps : 10000\n",
    "\n",
    "batch_size:\n",
    "  IC: 10\n",
    "  interior: 500\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Solver and training \n",
    "\n",
    "Now that we have the definitions for the various constraints and domains complete, we can form the solver and run the problem. The code to do the same can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make solver\n",
    "    slv = Solver(cfg, domain)\n",
    "\n",
    "    # start solver\n",
    "    slv.solve()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We have just completed the file set up for the problem. We are now ready to solve the system of ODEs using Neural Networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RANK\"]=\"0\"\n",
    "os.environ[\"WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"MASTER_ADDR\"]=\"localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../../source_code/spring_mass/spring_mass_solver.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the solution\n",
    "\n",
    "The .npz arrays can be plotted to visualize the output of the simulation. The .npz files that are created are found in the `outputs/` directory. The below figure shows the comparison of the neural network solution and the analytical solution. Again, we have a very good agreement in both the results. \n",
    "\n",
    "<img src=\"images/comparison.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "The below script shows an example of how the npz arrays can be plotted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "!{sys.executable} -m pip install ipympl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"outputs/spring_mass_solver/validators/\"\n",
    "\n",
    "# plot in 1d\n",
    "data = np.load(base_dir + \"validator.npz\", allow_pickle=True)\n",
    "data = np.atleast_1d(data.f.arr_0)[0]\n",
    "\n",
    "plt.plot(data[\"t\"], data[\"true_x1\"], label=\"True x1\")\n",
    "plt.plot(data[\"t\"], data[\"true_x2\"], label=\"True x2\")\n",
    "plt.plot(data[\"t\"], data[\"true_x3\"], label=\"True x3\")\n",
    "plt.plot(data[\"t\"], data[\"pred_x1\"], label=\"Pred x1\")\n",
    "plt.plot(data[\"t\"], data[\"pred_x2\"], label=\"Pred x2\")\n",
    "plt.plot(data[\"t\"], data[\"pred_x3\"], label=\"Pred x3\")\n",
    "plt.legend()\n",
    "plt.savefig('comparison_spring_mass.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the Inverse Problem\n",
    "\n",
    "Another important advantage of a neural network solver over traditional numerical methods is its ability to solve inverse problems. In an inverse problem, we start with a set of observations and then use those observations to calculate the causal factors that produced them. To demonstrate this concept, we will solve the same spring mass system in an inverse setting. Specifically, we will assume that the data for the displacements of the three masses $x_1, x_2 \\text{ and } x_3$ is available to us through the analytical solution and the first mass ($m_1$) and the last spring coefficient ($k_4$) is unknown. We will use the neural network to assimilate the displacements from the analytical solution and use it to invert out the unknown quantities from ODEs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Setup\n",
    "\n",
    "The equation file again remains the same for this part. Here, we will use the <code>PointwiseConstraint</code> class to assimilate the solution in the training data. We will make a network to memorize the three displacements by developing a mapping between $t$ and $(x_1, x_2, x_3)$. The second network will be trained to invert out the desired quantities viz. $(m_1, k_4)$. \n",
    "<h3 id=\"note\">Note</h3>\n",
    "Now we will describe the contents of the <a href=\"../../source_code/spring_mass/spring_mass_inverse.py\" rel=\"nofollow\"><code>spring_mass_inverse.py</code></a> script \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1,2 & 3:  Defining the equations, Networks and Nodes for an Inverse problem\n",
    "\n",
    "Since part of the problem involves memorizing the given solution, we will have `'t'` as input numpy array and `'x_1', 'x_2', 'x_3', 'ode_x1', 'ode_x2', 'ode_x3'` as the output numpy arrays. Setting `'x_1', 'x_2', 'x_3'` as input values from analytical data, we are essentially making the network assimilate the analytical distribution of these variables in the selected domain. Setting `'ode_x1', 'ode_x2', 'ode_x3'` equal to 0, we will also inform the network to satisfy the ODE losses at those sampled points. Now, assuming that we also know the initial conditions of the solution, except the `'m_1'` and `'k_4'`, all the variables in these ODEs are known. Thus the network can use this information to invert out the unknowns. The below code shows the data preparation step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import numpy as np\n",
    "from sympy import Symbol, Eq\n",
    "\n",
    "import modulus\n",
    "from modulus.sym.hydra import ModulusConfig, instantiate_arch\n",
    "from modulus.sym.solver import Solver\n",
    "from modulus.sym.domain import Domain\n",
    "from modulus.sym.geometry.primitives_1d import Point1D\n",
    "from modulus.sym.geometry import Parameterization\n",
    "from modulus.sym.domain.constraint import (\n",
    "    PointwiseBoundaryConstraint,\n",
    "    PointwiseConstraint,\n",
    ")\n",
    "from modulus.sym.domain.validator import PointwiseValidator\n",
    "from modulus.sym.domain.monitor import PointwiseMonitor\n",
    "from modulus.sym.key import Key\n",
    "from modulus.sym.node import Node\n",
    "\n",
    "from spring_mass_ode import SpringMass\n",
    "\n",
    "\n",
    "@modulus.sym.main(config_path=\"conf\", config_name=\"config_inverse\")\n",
    "def run(cfg: ModulusConfig) -> None:\n",
    "    # prepare data\n",
    "    t_max = 10.0\n",
    "    deltaT = 0.01\n",
    "    t = np.arange(0, t_max, deltaT)\n",
    "    t = np.expand_dims(t, axis=-1)\n",
    "\n",
    "    invar_numpy = {\"t\": t}\n",
    "    outvar_numpy = {\n",
    "        \"x1\": (1 / 6) * np.cos(t)\n",
    "        + (1 / 2) * np.cos(np.sqrt(3) * t)\n",
    "        + (1 / 3) * np.cos(2 * t),\n",
    "        \"x2\": (2 / 6) * np.cos(t)\n",
    "        + (0 / 2) * np.cos(np.sqrt(3) * t)\n",
    "        - (1 / 3) * np.cos(2 * t),\n",
    "        \"x3\": (1 / 6) * np.cos(t)\n",
    "        - (1 / 2) * np.cos(np.sqrt(3) * t)\n",
    "        + (1 / 3) * np.cos(2 * t),\n",
    "    }\n",
    "    outvar_numpy.update({\"ode_x1\": np.full_like(invar_numpy[\"t\"], 0)})\n",
    "    outvar_numpy.update({\"ode_x2\": np.full_like(invar_numpy[\"t\"], 0)})\n",
    "    outvar_numpy.update({\"ode_x3\": np.full_like(invar_numpy[\"t\"], 0)})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of creating neural networks for an inverse problem is similar to other problems we have seen in previous tutorials. However, as the information for the displacements, and in turn, their gradients (i.e. velocities and accelerations), is already present (from analytical data) for the network to memorize, we will detach these variables in the computation graph in their respective equations. This means that only the networks predicting `'m1'` and `'k4'` will be optimized to minimize the equation residuals. The displacements, velocities and accelerations are treated as ground truth data.\n",
    "\n",
    "Also, note that the mass and spring constant are passed in as Symbolic variables (`'m1'` and `'k4'` respectively) to the\n",
    "equations as they are unknowns in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make list of nodes to unroll graph on\n",
    "    sm = SpringMass(k=(2, 1, 1, \"k4\"), m=(\"m1\", 1, 1))\n",
    "    sm_net = instantiate_arch(\n",
    "        input_keys=[Key(\"t\")],\n",
    "        output_keys=[Key(\"x1\"), Key(\"x2\"), Key(\"x3\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "    invert_net = instantiate_arch(\n",
    "        input_keys=[Key(\"t\")],\n",
    "        output_keys=[Key(\"m1\"), Key(\"k4\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "\n",
    "    nodes = (\n",
    "        sm.make_nodes(\n",
    "            detach_names=[\n",
    "                \"x1\",\n",
    "                \"x1__t\",\n",
    "                \"x1__t__t\",\n",
    "                \"x2\",\n",
    "                \"x2__t\",\n",
    "                \"x2__t__t\",\n",
    "                \"x3\",\n",
    "                \"x3__t\",\n",
    "                \"x3__t__t\",\n",
    "            ]\n",
    "        )\n",
    "        + [sm_net.make_node(name=\"spring_mass_network\", jit=cfg.jit)]\n",
    "        + [invert_net.make_node(name=\"invert_network\", jit=cfg.jit)]\n",
    "    )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, we will use the solution coming from the analytical solution in the form of the numpy arrays we defined earlier. We will use the `PointwiseConstraint` class to handle such input data. The `PointwiseConstraint` class takes in separate dictionaries for input variables and output variables. These dictionaries have a key for each variable and a numpy array of values associated with the key. The below code shows the addition of the boundary constraint and the constraint coming from the numpy arrays we just defined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # add constraints to solver\n",
    "    # make geometry\n",
    "    geo = Point1D(0)\n",
    "    t_symbol = Symbol(\"t\")\n",
    "    x = Symbol(\"x\")\n",
    "    time_range = {t_symbol: (0, t_max)}\n",
    "\n",
    "    # make domain\n",
    "    domain = Domain()\n",
    "\n",
    "    # initial conditions\n",
    "    IC = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=geo,\n",
    "        outvar={\"x1\": 1.0, \"x2\": 0, \"x3\": 0, \"x1__t\": 0, \"x2__t\": 0, \"x3__t\": 0},\n",
    "        batch_size=cfg.batch_size.IC,\n",
    "        lambda_weighting={\n",
    "            \"x1\": 1.0,\n",
    "            \"x2\": 1.0,\n",
    "            \"x3\": 1.0,\n",
    "            \"x1__t\": 1.0,\n",
    "            \"x2__t\": 1.0,\n",
    "            \"x3__t\": 1.0,\n",
    "        },\n",
    "        parameterization=Parameterization({t_symbol: 0}),\n",
    "    )\n",
    "    domain.add_constraint(IC, name=\"IC\")\n",
    "\n",
    "    # data and pdes\n",
    "    data = PointwiseConstraint.from_numpy(\n",
    "        nodes=nodes,\n",
    "        invar=invar_numpy,\n",
    "        outvar=outvar_numpy,\n",
    "        batch_size=cfg.batch_size.data,\n",
    "    )\n",
    "    domain.add_constraint(data, name=\"Data\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Adding Monitors\n",
    "\n",
    "For this tutorial, we will monitor the convergence of average `'m_1'` and `'k_4'` inside the domain as the solution progresses. Once we find that the average value of these quantities have reached a steady value, we can end the simulation. The code to generate such monitors can be found below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # add monitors\n",
    "    monitor = PointwiseMonitor(\n",
    "        invar_numpy,\n",
    "        output_names=[\"m1\"],\n",
    "        metrics={\"mean_m1\": lambda var: torch.mean(var[\"m1\"])},\n",
    "        nodes=nodes,\n",
    "    )\n",
    "    domain.add_monitor(monitor)\n",
    "\n",
    "    monitor = PointwiseMonitor(\n",
    "        invar_numpy,\n",
    "        output_names=[\"k4\"],\n",
    "        metrics={\"mean_k4\": lambda var: torch.mean(var[\"k4\"])},\n",
    "        nodes=nodes,\n",
    "    )\n",
    "    domain.add_monitor(monitor)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Hydra configuration\n",
    "\n",
    "More information on the available configurations can be found in [Modulus Configuration](https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/features/configuration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "defaults :\n",
    "  - modulus_default\n",
    "  - arch:\n",
    "      - fully_connected\n",
    "  - scheduler: tf_exponential_lr\n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "arch:\n",
    "    fully_connected:\n",
    "        layer_size: 256\n",
    "\n",
    "save_filetypes : \"vtk,npz\"\n",
    "\n",
    "scheduler:\n",
    "  decay_rate: 0.95\n",
    "  decay_steps: 100\n",
    "\n",
    "training:\n",
    "  rec_results_freq: 1000\n",
    "  max_steps : 10000\n",
    "\n",
    "batch_size:\n",
    "  IC: 10\n",
    "  data: 1000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Solver and Training\n",
    "\n",
    "Now that we have the definitions for the various constraints and domains complete, we can form the solver and run the problem similar to before. The code to do the same can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make solver\n",
    "    slv = Solver(cfg, domain)\n",
    "\n",
    "    # start solver\n",
    "    slv.solve()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RANK\"]=\"0\"\n",
    "os.environ[\"WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"MASTER_ADDR\"]=\"localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../../source_code/spring_mass/spring_mass_inverse.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the solution - Inverse spring problem\n",
    "\n",
    "We can monitor the Tensorboard plots to see the convergence of the simulation and the final values of the $m_1$ and $k_4$. We see that after sufficient training, we get the $m_1$ and $k_4$ as 1 and 2 respectively. These were the same values that we used to create the analytical solution.\n",
    "\n",
    "1. The option to launch a Tensorboard then shows up in that directory.\n",
    "\n",
    "<center><img src=\"../projectile/images/tensorboard.png\" alt=\"Drawing\" style=\"width:900px\" /></center>\n",
    "\n",
    "2. We can launch tensorboard using the following command: \n",
    "\n",
    "```\n",
    "tensorboard --logdir /workspace/python/jupyter_notebook/ --port 8889\n",
    "```\n",
    "\n",
    "3. Open a new tab in your browser and head to [http://127.0.0.1:8889](http://127.0.0.1:8889) . You should see a screen similar to the below one. \n",
    "\n",
    "<center><img src=\"../projectile/images/tensorboard_browser.png\" alt=\"Drawing\" style=\"width:900px\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "Don't forget to check out additional [Open Hackathons Resources](https://www.openhackathons.org/s/technical-resources) and join our [OpenACC and Hackathons Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community.\n",
    "\n",
    "---\n",
    "\n",
    "# Licensing\n",
    "\n",
    "Copyright © 2023 OpenACC-Standard.org.  This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials may include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a711b04aa4c9aa07579ffc797b65c7dfc6f7ec2ead73841f0d3314704b4af09d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
