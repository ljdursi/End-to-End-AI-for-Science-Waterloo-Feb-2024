{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62cb463c",
   "metadata": {},
   "source": [
    "# Core: Training Weather prediction model using PhysicsNeMo\n",
    "\n",
    "In this notebook, we will emulate global weather system using a data-driven AI model. This notebook introduces FourCastNet architecture which is built using the Adaptive Fourier Neural Operators. This notebook is an extension of the simple data-driven problem we solved in [this notebook](../darcy_flow/Notebook_1.ipynb).\n",
    "\n",
    "#### Contents of the Notebook\n",
    "- [Problem Statement](#Problem-Statement:-Developing-an-AI-model-for-weather-forecasting-using-FourCastNet)\n",
    "- [FourCastNet (Adaptive Fourier Neural Operator)](#FourCastNet-(Adaptive-Fourier-Neural-Operator))\n",
    "- [Solving Weather Forecasting using FourCastNet](#Solving-weather-forecasting-using-FourCastNet)\n",
    "    - [Step 1: Setup DistributedManager and data loaders](#Step-1:-Setup-DistributedManager-and-data-loaders)\n",
    "    - [Step 2: Initialize the AFNO model](#Step-2:-Initialize-the-AFNO-model)\n",
    "    - [Step 3: Setup custom loss function and validation utilities](#Step-3:-Setup-custom-loss-function-and-validation-utilities)\n",
    "    - [Step 4: Setup distributed data parallel training, initialize optimizer and scheduler](#Step-4:-Setup-distributed-data-parallel-training,-initialize-optimizer-and-scheduler)\n",
    "    - [Step 5: Apply optimizations to speed-up training](#Step-5:-Apply-optimizations-to-speed-up-training)\n",
    "    - [Step 6: Setup training loop and train the model](#Step-6:-Setup-training-loop-and-train-the-model)\n",
    "    - [Step 7: Perform inference on the trained model](#Step-7:-Perform-inference-on-the-trained-model)\n",
    "\n",
    "#### Learning Objectives\n",
    "- How to use PhysicsNeMo to setup a weather prediction model\n",
    "- How to use Distributed and optimization utilities from PhysicsNeMo\n",
    "- How to perform inference on trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cf226f",
   "metadata": {},
   "source": [
    "## Problem Statement: Developing an AI model for weather forecasting using FourCastNet\n",
    "\n",
    "<strong>FourCastNet</strong>, short for Fourier ForeCasting Neural Network, is a global data-driven weather forecasting model that provides accurate short to medium range global predictions at 0.25° resolution. FourCastNet generates a week long forecast in less than 2 seconds, orders of magnitude faster than the ECMWF Integrated Forecasting System (IFS), a state-of-the-art Numerical Weather Prediction (NWP) model, with comparable or better accuracy. It is trained on a small subset of the ERA5 reanalysis dataset from the ECMWF, which consists of hourly estimates of several atmospheric variables at a latitude and longitude resolution of 0.25°. Given an initial condition from the ERA5 dataset as input, FourCastNet recursively applies an Adaptive Fourier Neural Operator (AFNO) network to predict their dynamics at later time steps. In the current iteration, FourCastNet forecasts 20 atmospheric variables. These variables, listed in the table below, are sampled from the ERA5 dataset at a temporal resolution of 6 hours.\n",
    "\n",
    "<center><img src=\"images/fcn_table.png\" alt=\"Drawing\" style=\"width:600px\" /></center>\n",
    "\n",
    "The goal of FourCastNet is to forecast modeled variables on a short time scale of up to 10 days. FourCastNet is initialized using an initial condition from the ERA5 reanalysis dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c57eb",
   "metadata": {},
   "source": [
    "## FourCastNet (Adaptive Fourier Neural Operator) \n",
    "\n",
    "FourCastNet uses Adaptive Fourier Neural Operator (AFNO) model. This particular neural network architecture is appealing as it is specifically designed for high-resolution inputs and synthesizes several key recent advances in Deep Learning into one model. Namely, it combines the Fourier Neural Operator (FNO) learning approach of <a href=\"https://arxiv.org/abs/2010.08895\" rel=\"nofollow\">Li et al. [2021a]</a>, which has been shown to perform well in modeling challenging PDE systems, with a powerful ViT backbone.\n",
    "\n",
    "<center><img src=\"images/fcn_arch.webp\" alt=\"Drawing\" style=\"width:900px\" /></center>\n",
    "\n",
    "The AFNO model is unique in that it frames the mixing operation as continuous global convolution, implemented efficiently in the Fourier domain with FFTs, which allows modeling dependencies across spatial and channel dimensions flexibly and scalably. With such a design, the spatial mixing complexity is reduced to $O(N log N)$, where $N$ is the number of image patches or tokens. This scaling allows the AFNO model to be well-suited to high-resolution data at the current 0.25◦ resolution. In the original FNO formulation, the operator learning approach showed impressive results in solving turbulent Navier-Stokes systems, so incorporating this into a data-driven atmospheric model is a natural choice.\n",
    "\n",
    "First, the input variables on the 720 × 1440 latitude-longitude grid are projected to a 2D grid (h × w) of patches (with a small patch size p × p, where e.g., p = 8), with each patch represented as a d-dimensional token. Then, the sequence of patches are fed, along with a positional encoding, to a series of AFNO layers. Each layer, given an input tensor of patches  $h×w×d$ , performs spatial mixing followed by channel mixing. Spatial mixing happens in the Fourier domain as follows: \n",
    "\n",
    "<strong>Step 1</strong> : Transform tokens to the Fourier domain with \n",
    "$$z_{m,n} = [DFT(X)]_{m,n} $$\n",
    "where $m, n$ index the patch location and DFT denotes a 2D discrete Fourier transform.\n",
    "\n",
    "<strong>Step 2</strong> : Apply token weighting in the Fourier domain, and promote sparsity with a Soft-Thresholding and Shrinkage operation as\n",
    "$$\\tilde{z}_{m,n} = S_λ(MLP(z_{m,n}))$$\n",
    "where $S_λ(x) = sign(x) max(|x| − λ, 0)$ with the sparsity controlling parameter $λ$, and MLP() is a 2-layer\n",
    "multi-layer perceptron with block-diagonal weight matrices, which are shared across all patches.\n",
    "\n",
    "<strong>Step 3</strong> : Inverse Fourier to transform back to the patch domain and add a residual connection as\n",
    "$$y_{m,n} = [IDFT(\\tilde{Z})]_{m,n} + X_{m,n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e785d",
   "metadata": {},
   "source": [
    "## Solving weather forecasting using FourCastNet\n",
    "\n",
    "With theory and basics covered, let's look into how to code up a weather forecasting example using PhysicsNeMo. Training these weather prediction models require handling very large volumes of data and typically involve training on multiple GPUs. With PhysicsNeMo we aim to provide utilities to facilitate this and simplify the process of setting up an optimized, scalable training pipeline for such large problems. In this example we will see the usage distributed utilities, optimization wrappers and dataloaders from PhysicsNeMo. \n",
    "\n",
    "In addition to the optimized utilities, PhysicsNeMo also has several implementations of weather models developed within NVIDIA and from the community to enable your exploration in this space and empower you to do faster science using deep learning and PhysicsNeMo. \n",
    "\n",
    "<center><img src=\"images/global-weather-models.png\" alt=\"Drawing\" style=\"width:1100px\" /></center>\n",
    "\n",
    "Now, let's start with a few imports and loading the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be697e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RANK\"]=\"0\"\n",
    "os.environ[\"WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"MASTER_ADDR\"]=\"localhost\"\n",
    "os.environ[\"MASTER_PORT\"]=\"15678\"\n",
    "\n",
    "import torch\n",
    "import hydra\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from physicsnemo.models.afno import AFNO\n",
    "from physicsnemo.datapipes.climate import ERA5HDF5Datapipe\n",
    "from physicsnemo.distributed import DistributedManager\n",
    "from physicsnemo.utils import StaticCaptureTraining, StaticCaptureEvaluateNoGrad\n",
    "\n",
    "from physicsnemo.launch.logging import LaunchLogger, PythonLogger, initialize_mlflow\n",
    "from physicsnemo.launch.utils import load_checkpoint, save_checkpoint\n",
    "\n",
    "from apex import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13351e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "\n",
    "initialize(version_base=\"1.3\", config_path=\"conf\")\n",
    "cfg = compose(config_name=\"config_weather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74327e42",
   "metadata": {},
   "source": [
    "### Step 1: Setup DistributedManager and data loaders\n",
    "\n",
    "We start with initializing utilities for distributed training. For this session, you have access to only 1 GPU, nevertheless we will setup the training in a distributed data parallel. This way, in the presence of multiple GPUs, we can minimize the time per epoch. Distributed utilities in PhysicsNeMo are designed to simplify implementation of parallel training and make inference scripts easier by providing a unified way to configure and query parameters associated with the distributed environment. The utilities in `physicsnemo.distributed` build on top of the utilities from `torch.distributed` and abstract out some of the complexities of setting up a distributed execution environment. For more details refer the documentation on [`physicsnemo.distributed`](https://docs.nvidia.com/deeplearning/physicsnemo/physicsnemo-core/api/physicsnemo.distributed.html).\n",
    "\n",
    "Once the `DistributedManager` is initialized, it can be used anytime in your training loop without reinitialization. The distributed manager from PhysicsNeMo will enable you query `device_ids`, `output_device`, `broadcast_buffers`, `find_unused_parameters` etc. parameters that are typically required to setup a distributed PyTorch training workflow. \n",
    "\n",
    "We also initialize dataloaders required to load the weather data to train this model. We will use a optimized dataloader from PhysicsNeMo that is built on top of NVIDIA DALI. This dataloader allows fast data loading of weather datasets and also enables asynchronous and parallel access of several data streams. Notice the use of `dist.device`, `dist.rank` and `dist.world_size`. \n",
    "\n",
    "#### Note\n",
    "While the actual AFNO model is trained on 20 channels of atmospheric data from 1979-2018, for the purposes of this notebook, we will only use a subset of this data which includes some samples from the year 1980 for channels U10 (10m u-component of wind), V10 (10m v-component of wind) and T2m (2m temperature). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48901b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DistributedManager.initialize()\n",
    "dist = DistributedManager()\n",
    "\n",
    "LaunchLogger.initialize(use_mlflow=cfg.use_mlflow)  # PhysicsNeMo launch logger\n",
    "logger = PythonLogger(\"main\")  # General python logger\n",
    "\n",
    "datapipe = ERA5HDF5Datapipe(\n",
    "    data_dir=\"../../source_code/core/datasets/test/\",\n",
    "    stats_dir=\"../../source_code/core/datasets/stats/\",\n",
    "    channels=[i for i in range(3)],\n",
    "    num_samples_per_year=128,\n",
    "    batch_size=2,\n",
    "    patch_size=(8, 8),\n",
    "    num_workers=cfg.num_workers_train,\n",
    "    device=dist.device,\n",
    "    process_rank=dist.rank,\n",
    "    world_size=dist.world_size,\n",
    ")\n",
    "\n",
    "logger.success(f\"Loaded datapipe of size {len(datapipe)}\")\n",
    "if dist.rank == 0:\n",
    "    logger.file_logging()\n",
    "    validation_datapipe = ERA5HDF5Datapipe(\n",
    "        data_dir=\"../../source_code/core/datasets/out_of_sample/\",\n",
    "        stats_dir=\"../../source_code/core/datasets/stats/\",\n",
    "        channels=[i for i in range(3)],\n",
    "        num_steps=8,\n",
    "        num_samples_per_year=4,\n",
    "        batch_size=1,\n",
    "        patch_size=(8, 8),\n",
    "        device=dist.device,\n",
    "        num_workers=cfg.num_workers_validation,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "logger.success(f\"Loaded validaton datapipe of size {len(validation_datapipe)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea24843",
   "metadata": {},
   "source": [
    "### Step 2: Initialize the AFNO model\n",
    "\n",
    "Next, we initialize the AFNO model from PhysicsNeMo with the appropriate parameters required for the FourCastNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa10a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = AFNO(\n",
    "    inp_shape=[720, 1440],\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    patch_size=[8, 8],\n",
    "    embed_dim=768,\n",
    "    depth=12,\n",
    "    num_blocks=8,\n",
    ").to(dist.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7f612",
   "metadata": {},
   "source": [
    "### Step 3: Setup custom loss function and validation utilities\n",
    "\n",
    "Next, we define the loss function for training and the validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50324d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, y, p=2.0):\n",
    "    yv = y.reshape(x.size()[0], -1)\n",
    "    xv = x.reshape(x.size()[0], -1)\n",
    "    diff_norms = torch.linalg.norm(xv - yv, ord=p, dim=1)\n",
    "    y_norms = torch.linalg.norm(yv, ord=p, dim=1)\n",
    "\n",
    "    return torch.mean(diff_norms / y_norms)\n",
    "\n",
    "os.makedirs(\"./results/\", exist_ok=True)\n",
    "@torch.no_grad()\n",
    "def validation_step(eval_step, fcn_model, datapipe, channels=[0, 1], epoch=0):\n",
    "    loss_epoch = 0\n",
    "    num_examples = 0  # Number of validation examples\n",
    "    # Dealing with DDP wrapper\n",
    "    if hasattr(fcn_model, \"module\"):\n",
    "        fcn_model = fcn_model.module\n",
    "    fcn_model.eval()\n",
    "    for i, data in enumerate(datapipe):\n",
    "        invar = data[0][\"invar\"].detach()\n",
    "        outvar = data[0][\"outvar\"].cpu().detach()\n",
    "        predvar = torch.zeros_like(outvar)\n",
    "\n",
    "        for t in range(outvar.shape[1]):\n",
    "            output = eval_step(fcn_model, invar)\n",
    "            invar.copy_(output)\n",
    "            predvar[:, t] = output.detach().cpu()\n",
    "\n",
    "        num_elements = torch.prod(torch.Tensor(list(predvar.shape[1:])))\n",
    "        loss_epoch += torch.sum(torch.pow(predvar - outvar, 2)) / num_elements\n",
    "        num_examples += predvar.shape[0]\n",
    "\n",
    "        # Plotting\n",
    "        if i == 0:\n",
    "            predvar = predvar.numpy()\n",
    "            outvar = outvar.numpy()\n",
    "            for chan in channels:\n",
    "                plt.close(\"all\")\n",
    "                fig, ax = plt.subplots(\n",
    "                    3, predvar.shape[1], figsize=(15, predvar.shape[0] * 5)\n",
    "                )\n",
    "                for t in range(outvar.shape[1]):\n",
    "                    ax[0, t].imshow(predvar[0, t, chan])\n",
    "                    ax[1, t].imshow(outvar[0, t, chan])\n",
    "                    ax[2, t].imshow(predvar[0, t, chan] - outvar[0, t, chan])\n",
    "\n",
    "                fig.savefig(f\"./results/era5_validation_channel{chan}_epoch{epoch}.png\")\n",
    "\n",
    "    fcn_model.train()\n",
    "    return loss_epoch / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4bc0e0",
   "metadata": {},
   "source": [
    "### Step 4: Setup distributed data parallel training, initialize optimizer and scheduler\n",
    "\n",
    "Here, we setup the distributed data parallel training. `DistributedDataParallel` in PyTorch provides the framework for data parallel training by reducing parameter gradients across multiple worker processes after the backward pass. We will use the previously initialized `DistributedManager` from physicsnemo to set this up. Finally, we also define the optimizer and scheduler for the training. For this example we will use a FusedAdam optimizer and a Cosine annealing for learning rate schedule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd11619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed learning\n",
    "if dist.world_size > 1:\n",
    "    ddps = torch.cuda.Stream()\n",
    "    with torch.cuda.stream(ddps):\n",
    "        fcn_model = DistributedDataParallel(\n",
    "            fcn_model,\n",
    "            device_ids=[dist.local_rank],\n",
    "            output_device=dist.device,\n",
    "            broadcast_buffers=dist.broadcast_buffers,\n",
    "            find_unused_parameters=dist.find_unused_parameters,\n",
    "        )\n",
    "    torch.cuda.current_stream().wait_stream(ddps)\n",
    "\n",
    "# Initialize optimizer and scheduler\n",
    "optimizer = optimizers.FusedAdam(\n",
    "    fcn_model.parameters(), betas=(0.9, 0.999), lr=0.0005, weight_decay=0.0\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c94f2",
   "metadata": {},
   "source": [
    "### Step 5: Apply optimizations to speed-up training\n",
    "\n",
    "Using the models from PhysicsNeMo enables you to use some optimizations like CUDA Graphs, Automatic Mixed Precision and JIT in an automated fashion. `StaticCaptureTraining` and `StaticCaptureEvaluateNoGrad` decorator will capture the training step function and optimize it for the specified choices. To enable these optimizations, we simply wrap the models forward pass and the evaluation step using these decorators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@StaticCaptureEvaluateNoGrad(model=fcn_model, logger=logger, use_graphs=False)\n",
    "def eval_step_forward(my_model, invar):\n",
    "    return my_model(invar)\n",
    "\n",
    "@StaticCaptureTraining(model=fcn_model, optim=optimizer, logger=logger)\n",
    "def train_step_forward(my_model, invar, outvar):\n",
    "    # Multi-step prediction\n",
    "    loss = 0\n",
    "    # Multi-step not supported\n",
    "    for t in range(outvar.shape[1]):\n",
    "        outpred = my_model(invar)\n",
    "        invar = outpred\n",
    "        loss += loss_func(outpred, outvar[:, t])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93723ff1",
   "metadata": {},
   "source": [
    "### Step 6: Setup training loop and train the model\n",
    "\n",
    "Once all the required utilities are instantiated and the functions defined, we can setup the training loop as before. We loop through the entire dataset and repeat that for a fixed epochs. For this example, to keep the training time short, we will load a pre-computed checkpoint and train the model only for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e3f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Attempt to load latest checkpoint if one exists\n",
    "loaded_epoch = load_checkpoint(\n",
    "    \"./../../source_code/core/checkpoints\",\n",
    "    models=fcn_model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=dist.device,\n",
    ")\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(max(1, loaded_epoch + 1), loaded_epoch + 2):\n",
    "    # Wrap epoch in launch logger for console / WandB logs\n",
    "    with LaunchLogger(\n",
    "        \"train\", epoch=epoch, num_mini_batch=len(datapipe), epoch_alert_freq=10\n",
    "    ) as log:\n",
    "        # === Training step ===\n",
    "        for j, data in enumerate(datapipe):\n",
    "            invar = data[0][\"invar\"]\n",
    "            outvar = data[0][\"outvar\"]\n",
    "            loss = train_step_forward(fcn_model, invar, outvar)\n",
    "            log.log_minibatch({\"loss\": loss.detach()})\n",
    "        log.log_epoch({\"Learning Rate\": optimizer.param_groups[0][\"lr\"]})\n",
    "    if dist.rank == 0:\n",
    "        # Wrap validation in launch logger for console / WandB logs\n",
    "        with LaunchLogger(\"valid\", epoch=epoch) as log:\n",
    "            # === Validation step ===\n",
    "            error = validation_step(\n",
    "                eval_step_forward, fcn_model, validation_datapipe, epoch=epoch, channels=[0]\n",
    "            )\n",
    "            log.log_epoch({\"Validation error\": error})\n",
    "    if dist.world_size > 1:\n",
    "        torch.distributed.barrier()\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Use PhysicsNeMo Launch checkpoint\n",
    "    if dist.rank == 0:\n",
    "        save_checkpoint(\n",
    "            \"./checkpoints\",\n",
    "            models=fcn_model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "\n",
    "if dist.rank == 0:\n",
    "    logger.info(\"Finished training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc21b1d",
   "metadata": {},
   "source": [
    "You can now visualize the results of the training by looking at the outputs from the `results` directory. That completes the training of our weather prediction data-driven model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210adf6f",
   "metadata": {},
   "source": [
    "# Important: Free up GPU Memory!\n",
    "\n",
    "Run the below cell to free up GPU memory after training the model before moving to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63cb9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1f54a0",
   "metadata": {},
   "source": [
    "### Step 7: Perform inference on the trained model\n",
    "\n",
    "Now that we have trained our AI weather prediction model, this enables us to do some cool science with it. Specifically it enables you to compute ensemble forecasts of the model at a very fast speed compared to a traditional Numerical Weather Prediction models. While showcasing the ensemble computation is out of the scope of this introductory content, below we demonstrate how one can run a simple inference from a trained model. You can refer to [Earth2MIP](https://github.com/NVIDIA/earth2mip) for more information about model scoring and diagnostics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4307fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pre-trained checkpoint from NGC registry\n",
    "# The model is already downloaded for you, but below is a snippets which helps you download for your personal machine.\n",
    "#!wget 'https://api.ngc.nvidia.com/v2/models/nvidia/modulus/modulus_fcn/versions/v0.2/files/fcn.zip'\n",
    "!unzip ../../source_code/core/fcn.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd917377",
   "metadata": {},
   "source": [
    "Once the checkpoint is downloaded, you can run some simple inference with the model. For this example, we have already provided you with a initial condition downloaded from [GFS](https://www.ncei.noaa.gov/products/weather-climate-models/global-forecast).\n",
    "\n",
    "**Note:** The downloaded checkpoint is a variation of the original AFNO model. The checkpoint hosted on NGC was trained on 26 channels of weather data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# \n",
    "# If this cell looks like it's been stuck for sometime, \n",
    "# kindly check the output files to verify as it might have completed the file generation.\n",
    "################################# \n",
    "\n",
    "import torch\n",
    "import xarray\n",
    "import numpy as np\n",
    "import physicsnemo\n",
    "from physicsnemo.distributed import DistributedManager\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the PhysicsNeMo checkpoint\n",
    "# All the meta-data is already stored, so no need to instantiate the model\n",
    "model = physicsnemo.Module.from_checkpoint(\"./fcn/fcn.mdlus\")\n",
    "device = DistributedManager().device\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load the initial condition\n",
    "ic = xarray.open_dataset(\"./../../source_code/core/2024-01-01T00_00_00-subsampled.nc\")[\"fields\"]\n",
    "\n",
    "# Load the mean and standard deviation to normalize the inputs\n",
    "mean = np.load(\"./fcn/global_means.npy\")\n",
    "std = np.load(\"./fcn/global_stds.npy\")\n",
    "\n",
    "# Normalize the initial condition\n",
    "ic_norm = (ic - mean) / std \n",
    "\n",
    "# Create a tensor input\n",
    "ic_norm = torch.from_numpy(ic_norm.values).to(device).to(torch.float32)\n",
    "\n",
    "# Convert the output from 721x1440 -> 720x1440\n",
    "ic_norm = ic_norm[:,:,:720,:]\n",
    "\n",
    "# Generate an auto-regressive inference for 8 rollouts (8*6 = 48hr forecast)\n",
    "outputs=[]\n",
    "with torch.no_grad():\n",
    "    for i in range(8):\n",
    "        if i == 0:\n",
    "            out = model(ic_norm)\n",
    "        else:\n",
    "            out = model(out)\n",
    "        outputs.append(out)\n",
    "\n",
    "# Plot the results\n",
    "figsize = (5 * 8, 5)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=figsize,)\n",
    "\n",
    "for i in range(8):\n",
    "    out_numpy = outputs[i].cpu().numpy()\n",
    "\n",
    "    # un-normalize\n",
    "    out_numpy = out_numpy * std + mean\n",
    "    axes[i].imshow(out_numpy[0, 0])  # plot the first channel\n",
    "    axes[i].set_title(f\"Lead time {i*6} hrs.\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FCN.jpg\")\n",
    "\n",
    "################################# \n",
    "# If this cell looks like it's been stuck for sometime, \n",
    "# kindly check the output files to verify as it might have completed the file generation.\n",
    "################################# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff8ead",
   "metadata": {},
   "source": [
    "# Important: Free up GPU Memory!\n",
    "\n",
    "Run the below cell to free up GPU memory after training the model before moving to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f65af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8885247b",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "Don't forget to check out additional [Open Hackathons Resources](https://www.openhackathons.org/s/technical-resources) and join our [OpenACC and Hackathons Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community.\n",
    "\n",
    "---\n",
    "\n",
    "# Licensing\n",
    "\n",
    "Copyright © 2023 OpenACC-Standard.org.  This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials may include references to hardware and software developed by other entities; all applicable licensing and copyrights apply.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
